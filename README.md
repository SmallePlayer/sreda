# SREDA – Голосовой ассистент с модульной архитектурой

SREDA (Среда) - это расширяемый голосовой ассистент с графическим интерфейсом, разработанный с использованием модульной архитектуры. Проект включает в себя функции распознавания речи, взаимодействия с устройствами через TCP-сервер и интеграции с внешними API.

## Возможности

- Распознавание речи на русском языке с помощью Vosk
- Графический интерфейс пользователя (GUI)
- Взаимодействие с внешними устройствами через TCP-сервер
- Интеграция с Weather API для получения информации о погоде
- Локальная обработка с помощью Ollama
- Хранение данных в SQLite

## Архитектура проекта

```
src/
  app/                    # Приложения и GUI
    gui.py              # Графический интерфейс
  core/                   # Ядро системы
    llm.py              # Логика промптинга и разбор ответов
    db.py               # Работа с базой данных SQLite
  devices/                # Работа с внешними устройствами
    esp_server.py       # TCP сервер для взаимодействия с устройствами
  services/               # Сервисы и интеграции
    db.py               # Работа с базой данных сервисов
    weather.py          # Запросы к Weather API
    weather_printer.py  # Форматированный вывод погоды
  config/                 # Конфигурация
    settings.py         # Загрузка конфигурации из .env
```

## Запуск

### Требования

- Python 3.8+
- Vosk модель для распознавания речи
- Ollama для локальной обработки
- Доступ к интернету для Weather API

### Установка

1. Клонируйте репозиторий:
   ```bash
   git clone <url>
   cd sreda
   ```

2. Создайте и активируйте виртуальное окружение:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # или
   venv\Scripts\activate     # Windows
   ```

3. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```

4. Установите модель Vosk:
   ```bash
   mkdir -p models
   cd models
   wget https://alphacep.com/vosk/models/vosk-model-small-ru-0.22.zip
   unzip vosk-model-small-ru-0.22.zip
   mv vosk-model-small-ru-0.22 small_model
   ```

5. Создайте файл `.env` и заполните необходимые переменные окружения (см. раздел "Конфигурация")

### Запуск компонентов

- Запуск голосового ассистента:
  ```bash
  python voice_assistant.py
  ```

- Запуск TCP-сервера для устройств:
  ```bash
  python src/devices/esp_server.py
  ```

- Запуск графического интерфейса:
  ```bash
  python src/app/gui.py
  ```

## Конфигурация

Создайте файл `.env` в корне проекта со следующими переменными:

```
WEATHER_API_KEY=your_weather_api_key
VOSK_MODEL_DIR=models/small_model
OLLAMA_MODEL=qwen3:0.6b
```

### Описание переменных

- `WEATHER_API_KEY`: API ключ для Weather API (https://www.weatherapi.com/)
- `VOSK_MODEL_DIR`: Путь к модели Vosk для распознавания речи
- `OLLAMA_MODEL`: Название модели для Ollama (должна быть предварительно загружена)

## Структура моделей

```
models/
  big_model/     # Большая модель Vosk (более точная, но медленная)
  small_model/   # Маленькая модель Vosk (менее точная, но быстрая)
```

## Разработка

### Структура кода

- Все модули находятся в директории `src/`
- Импорты внутри модулей абсолютные
- Для запуска модулей используйте `python -m ...`

### Добавление новых функций

1. Создайте новый модуль в соответствующей директории (`src/services/` для сервисов, `src/devices/` для устройств)
2. Реализуйте необходимую логику
3. Добавьте интеграцию в основной поток выполнения (например, в `voice_assistant.py`)

### Тестирование

(Пока тесты не реализованы, но рекомендуется добавить их в будущем)

## Заметки по миграции

- Старые файлы не удалены. Новые входные точки используют модули из `src/`.
- Импорты внутри новых модулей абсолютные, запускать через `python -m ...`.

## Лицензия

(Укажите лицензию вашего проекта)

## Контрибьюторы

(Укажите информацию о контрибьюторах, если есть)
